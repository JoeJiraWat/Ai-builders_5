{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TFbIOlqzigO",
        "outputId": "41252a72-a482-4ffa-a551-e1911b0c49d7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install crepe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-k2xbdCp0kAW",
        "outputId": "465da631-16e9-4051-ba32-48e0a2d94cbc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting crepe\n",
            "  Downloading crepe-0.0.16.tar.gz (16 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from crepe) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from crepe) (1.15.3)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from crepe) (3.10.0)\n",
            "Collecting resampy>=0.2.0 (from crepe)\n",
            "  Downloading resampy-0.4.3-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from crepe) (3.13.0)\n",
            "Collecting hmmlearn>=0.3.0 (from crepe)\n",
            "  Downloading hmmlearn-0.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from crepe) (2.37.0)\n",
            "Requirement already satisfied: scikit-learn>=0.16 in /usr/local/lib/python3.11/dist-packages (from crepe) (1.6.1)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.11/dist-packages (from imageio>=2.3.0->crepe) (11.2.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->crepe) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->crepe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->crepe) (4.58.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->crepe) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->crepe) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->crepe) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->crepe) (2.9.0.post0)\n",
            "Requirement already satisfied: numba>=0.53 in /usr/local/lib/python3.11/dist-packages (from resampy>=0.2.0->crepe) (0.60.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.16->crepe) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.16->crepe) (3.6.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.53->resampy>=0.2.0->crepe) (0.43.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->crepe) (1.17.0)\n",
            "Downloading hmmlearn-0.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (165 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m165.9/165.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading resampy-0.4.3-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: crepe\n",
            "  Building wheel for crepe (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for crepe: filename=crepe-0.0.16-py3-none-any.whl size=134848677 sha256=2c926b865e1c1160cba5bc5dec30299a66abf01b05b987ea4eea9effc7d306a4\n",
            "  Stored in directory: /root/.cache/pip/wheels/fb/54/e2/e2d6bc065d4bbd6920e243682536fe85bb3b33daacbbeb9672\n",
            "Successfully built crepe\n",
            "Installing collected packages: resampy, hmmlearn, crepe\n",
            "Successfully installed crepe-0.0.16 hmmlearn-0.3.3 resampy-0.4.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "IQMkD3DLy6VK"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import librosa\n",
        "import crepe\n",
        "import joblib\n",
        "import soundfile as sf\n",
        "from music21 import pitch, stream, note, key\n",
        "from scipy.signal import butter, filtfilt, resample\n",
        "from tqdm import tqdm\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "config"
      ],
      "metadata": {
        "id": "sL6onsDi0etZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "STYLE_CSV_PATH = \"/content/drive/MyDrive/Datasets_For_Ai_builders/listSongDatasets - listSongDatasets(1).csv\"  # path to your CSV\n",
        "GENDER_MODEL_PATH = \"/content/drive/MyDrive/Datasets_For_Ai_builders/Models/voice_clssification_gender_model.pkl\"\n",
        "INPUT_AUDIO_DIR = \"/content/drive/MyDrive/Datasets_For_Ai_builders/CleanVoice_v2/\"\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/Datasets_For_Ai_builders/outputPipline/\"\n",
        "TARGET_SR = 16000\n",
        "STYLE_DIM = 31"
      ],
      "metadata": {
        "id": "4eKUgDmc0efL"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "setup"
      ],
      "metadata": {
        "id": "DTnzUSXC0ivF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "style_df = pd.read_csv(STYLE_CSV_PATH)\n",
        "gender_model = joblib.load(GENDER_MODEL_PATH)"
      ],
      "metadata": {
        "id": "tNhVba1e0iff"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "24 common key signatures"
      ],
      "metadata": {
        "id": "aDVXX5r50puF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "KEY_LIST = [\n",
        "    'C major', 'G major', 'D major', 'A major', 'E major', 'B major', 'F# major', 'C# major', 'G# major', 'D# major', 'A# major', 'F major',\n",
        "    'A minor', 'E minor', 'B minor', 'F# minor', 'C# minor', 'G# minor', 'D# minor', 'A# minor', 'F minor', 'C minor', 'G minor', 'D minor'\n",
        "]\n",
        "KEY2IDX = {k: i for i, k in enumerate(KEY_LIST)}\n",
        "\n",
        "def butter_filter(data, cutoff, fs, btype, order=5):\n",
        "    nyq = 0.5 * fs\n",
        "    norm_cutoff = cutoff / nyq\n",
        "    b, a = butter(order, norm_cutoff, btype=btype)\n",
        "    return filtfilt(b, a, data)\n",
        "\n",
        "def apply_filter(y, sr):\n",
        "    y = y / np.max(np.abs(y))\n",
        "    y_rs = resample(y, int(len(y) * TARGET_SR / sr))\n",
        "    low = butter_filter(y_rs, 1000, TARGET_SR, 'low')\n",
        "    high = butter_filter(y_rs, 500, TARGET_SR, 'high')\n",
        "    combined = low + high\n",
        "    return combined / np.max(np.abs(combined))\n",
        "\n",
        "def detect_gender(y, sr):\n",
        "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=17)  # เปลี่ยนเป็น 17\n",
        "    mfcc_mean = np.mean(mfcc, axis=1)\n",
        "    gender = gender_model.predict([mfcc_mean])[0]\n",
        "    return gender\n",
        "\n",
        "def detect_key_signature(y, sr):\n",
        "    y_trimmed, _ = librosa.effects.trim(y, top_db=40)\n",
        "    time, freq, conf, _ = crepe.predict(y_trimmed, sr, viterbi=True, step_size=10)\n",
        "    filtered = freq[conf > 0.8]\n",
        "    s = stream.Stream()\n",
        "    for f in filtered:\n",
        "        try:\n",
        "            p = pitch.Pitch()\n",
        "            p.frequency = f\n",
        "            s.append(note.Note(p))\n",
        "        except:\n",
        "            continue\n",
        "    try:\n",
        "        key_sig = s.analyze('key')\n",
        "        return f\"{key_sig.tonic.name} {key_sig.mode}\"\n",
        "    except:\n",
        "        return \"Unknown\"\n",
        "\n",
        "def build_style_vector(row, gender, key_sig):\n",
        "    vec = np.zeros(STYLE_DIM)\n",
        "    vec[:5] = [row['sweet'], row['soft'], row['clear'], row['powerful'], row['high']]\n",
        "    vec[5:7] = [1, 0] if gender == 'male' else [0, 1]\n",
        "    if key_sig in KEY2IDX:\n",
        "        vec[7 + KEY2IDX[key_sig]] = 1\n",
        "    return vec\n",
        "\n",
        "def extract_mel(y, sr):\n",
        "    mel = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
        "    mel_db = librosa.power_to_db(mel, ref=np.max)\n",
        "    return torch.tensor(mel_db, dtype=torch.float32)\n"
      ],
      "metadata": {
        "id": "XeiyTNAP0qE-"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "main pipline"
      ],
      "metadata": {
        "id": "ei_bIOl_0stR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for fname in tqdm(os.listdir(INPUT_AUDIO_DIR)):\n",
        "    if not fname.endswith(\".wav\"): continue\n",
        "    filepath = os.path.join(INPUT_AUDIO_DIR, fname)\n",
        "    y, sr = librosa.load(filepath, sr=None, mono=True)\n",
        "\n",
        "    y_filtered = apply_filter(y, sr)\n",
        "    gender = detect_gender(y_filtered, TARGET_SR)\n",
        "    key_sig = detect_key_signature(y_filtered, TARGET_SR)\n",
        "\n",
        "    row = style_df[style_df['filename'] == fname].iloc[0]\n",
        "    style_vec = build_style_vector(row, gender, key_sig)\n",
        "    mel = extract_mel(y_filtered, TARGET_SR)\n",
        "\n",
        "    output = {\n",
        "        'mel': mel,\n",
        "        'style': torch.tensor(style_vec, dtype=torch.float32),\n",
        "        'meta': {\n",
        "            'gender': gender,\n",
        "            'key_signature': key_sig,\n",
        "            'filename': fname\n",
        "        }\n",
        "    }\n",
        "    torch.save(output, os.path.join(OUTPUT_DIR, fname.replace(\".wav\", \".pt\")))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-V0I4r90smh",
        "outputId": "4d925ade-f4b9-442d-8f55-08b707e3a4dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/353 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m201/497\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m8:25\u001b[0m 2s/step"
          ]
        }
      ]
    }
  ]
}